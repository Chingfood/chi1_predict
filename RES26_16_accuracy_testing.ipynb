{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Orginal implementation from keras_contrib/layer/normalization\n",
    "# =============================================================================\n",
    "#from __future__ import absolute_import\n",
    "#from __future__ import division\n",
    "#from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "#import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "class GroupNormalization(tf.keras.layers.Layer):\n",
    "    \"\"\"Group normalization layer.\n",
    "    Group Normalization divides the channels into groups and computes\n",
    "    within each group the mean and variance for normalization.\n",
    "    Empirically, its accuracy is more stable than batch norm in a wide\n",
    "    range of small batch sizes, if learning rate is adjusted linearly\n",
    "    with batch sizes.\n",
    "    Relation to Layer Normalization:\n",
    "    If the number of groups is set to 1, then this operation becomes identical\n",
    "    to Layer Normalization.\n",
    "    Relation to Instance Normalization:\n",
    "    If the number of groups is set to the\n",
    "    input dimension (number of groups is equal\n",
    "    to number of channels), then this operation becomes\n",
    "    identical to Instance Normalization.\n",
    "    Arguments\n",
    "        groups: Integer, the number of groups for Group Normalization.\n",
    "            Can be in the range [1, N] where N is the input dimension.\n",
    "            The input dimension must be divisible by the number of groups.\n",
    "        axis: Integer, the axis that should be normalized.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    Output shape\n",
    "        Same shape as input.\n",
    "    References\n",
    "        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 groups=2,\n",
    "                 axis=-1,\n",
    "                 epsilon=1e-3,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(GroupNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.groups = groups\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = tf.keras.initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = tf.keras.initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = tf.keras.regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = tf.keras.regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = tf.keras.constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = tf.keras.constraints.get(gamma_constraint)\n",
    "        self._check_axis()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self._check_if_input_shape_is_none(input_shape)\n",
    "        self._set_number_of_groups_for_instance_norm(input_shape)\n",
    "        self._check_size_of_dimensions(input_shape)\n",
    "        self._create_input_spec(input_shape)\n",
    "\n",
    "        self._add_gamma_weight(input_shape)\n",
    "        self._add_beta_weight(input_shape)\n",
    "        self.built = True\n",
    "        super(GroupNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        input_shape = tf.keras.backend.int_shape(inputs)\n",
    "        tensor_input_shape = tf.shape(inputs)\n",
    "\n",
    "        reshaped_inputs, group_shape = self._reshape_into_groups(\n",
    "            inputs, input_shape, tensor_input_shape)\n",
    "\n",
    "        normalized_inputs = self._apply_normalization(reshaped_inputs,\n",
    "                                                      input_shape)\n",
    "\n",
    "        outputs = tf.reshape(normalized_inputs, tensor_input_shape)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'groups':\n",
    "            self.groups,\n",
    "            'axis':\n",
    "            self.axis,\n",
    "            'epsilon':\n",
    "            self.epsilon,\n",
    "            'center':\n",
    "            self.center,\n",
    "            'scale':\n",
    "            self.scale,\n",
    "            'beta_initializer':\n",
    "            tf.keras.initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer':\n",
    "            tf.keras.initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer':\n",
    "            tf.keras.regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer':\n",
    "            tf.keras.regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint':\n",
    "            tf.keras.constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint':\n",
    "            tf.keras.constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(GroupNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def _reshape_into_groups(self, inputs, input_shape, tensor_input_shape):\n",
    "\n",
    "        group_shape = [tensor_input_shape[i] for i in range(len(input_shape))]\n",
    "        group_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        group_shape.insert(self.axis, self.groups)\n",
    "        group_shape = tf.stack(group_shape)\n",
    "        reshaped_inputs = tf.reshape(inputs, group_shape)\n",
    "        return reshaped_inputs, group_shape\n",
    "\n",
    "    def _apply_normalization(self, reshaped_inputs, input_shape):\n",
    "\n",
    "        group_shape = tf.keras.backend.int_shape(reshaped_inputs)\n",
    "        group_reduction_axes = list(range(1, len(group_shape)))\n",
    "        axis = -2 if self.axis == -1 else self.axis - 1\n",
    "        group_reduction_axes.pop(axis)\n",
    "\n",
    "        mean, variance = tf.nn.moments(\n",
    "            reshaped_inputs, group_reduction_axes, keepdims=True)\n",
    "\n",
    "        gamma, beta = self._get_reshaped_weights(input_shape)\n",
    "        normalized_inputs = tf.nn.batch_normalization(\n",
    "            reshaped_inputs,\n",
    "            mean=mean,\n",
    "            variance=variance,\n",
    "            scale=gamma,\n",
    "            offset=beta,\n",
    "            variance_epsilon=self.epsilon)\n",
    "        return normalized_inputs\n",
    "\n",
    "    def _get_reshaped_weights(self, input_shape):\n",
    "        broadcast_shape = self._create_broadcast_shape(input_shape)\n",
    "        gamma = None\n",
    "        beta = None\n",
    "        if self.scale:\n",
    "            gamma = tf.reshape(self.gamma, broadcast_shape)\n",
    "\n",
    "        if self.center:\n",
    "            beta = tf.reshape(self.beta, broadcast_shape)\n",
    "        return gamma, beta\n",
    "\n",
    "    def _check_if_input_shape_is_none(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                             'input tensor should have a defined dimension '\n",
    "                             'but the layer received an input with shape ' +\n",
    "                             str(input_shape) + '.')\n",
    "\n",
    "    def _set_number_of_groups_for_instance_norm(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "\n",
    "        if self.groups == -1:\n",
    "            self.groups = dim\n",
    "\n",
    "    def _check_size_of_dimensions(self, input_shape):\n",
    "\n",
    "        dim = input_shape[self.axis]\n",
    "        if dim < self.groups:\n",
    "            raise ValueError(\n",
    "                'Number of groups (' + str(self.groups) + ') cannot be '\n",
    "                'more than the number of channels (' + str(dim) + ').')\n",
    "\n",
    "        if dim % self.groups != 0:\n",
    "            raise ValueError(\n",
    "                'Number of groups (' + str(self.groups) + ') must be a '\n",
    "                'multiple of the number of channels (' + str(dim) + ').')\n",
    "\n",
    "    def _check_axis(self):\n",
    "\n",
    "        if self.axis == 0:\n",
    "            raise ValueError(\n",
    "                \"You are trying to normalize your batch axis. Do you want to \"\n",
    "                \"use tf.layer.batch_normalization instead\")\n",
    "\n",
    "    def _create_input_spec(self, input_shape):\n",
    "\n",
    "        dim = input_shape[self.axis]\n",
    "        self.input_spec = tf.keras.layers.InputSpec(\n",
    "            ndim=len(input_shape), axes={self.axis: dim})\n",
    "\n",
    "    def _add_gamma_weight(self, input_shape):\n",
    "\n",
    "        dim = input_shape[self.axis]\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(\n",
    "                shape=shape,\n",
    "                name='gamma',\n",
    "                initializer=self.gamma_initializer,\n",
    "                regularizer=self.gamma_regularizer,\n",
    "                constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "\n",
    "    def _add_beta_weight(self, input_shape):\n",
    "\n",
    "        dim = input_shape[self.axis]\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(\n",
    "                shape=shape,\n",
    "                name='beta',\n",
    "                initializer=self.beta_initializer,\n",
    "                regularizer=self.beta_regularizer,\n",
    "                constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "\n",
    "    def _create_broadcast_shape(self, input_shape):\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        broadcast_shape.insert(self.axis, self.groups)\n",
    "        return broadcast_shape\n",
    "\n",
    "\n",
    "class InstanceNormalization(GroupNormalization):\n",
    "    \"\"\"Instance normalization layer.\n",
    "    Instance Normalization is an specific case of ```GroupNormalization```since\n",
    "    it normalizes all features of one channel. The Groupsize is equal to the\n",
    "    channel size. Empirically, its accuracy is more stable than batch norm in a\n",
    "    wide range of small batch sizes, if learning rate is adjusted linearly\n",
    "    with batch sizes.\n",
    "    Arguments\n",
    "        axis: Integer, the axis that should be normalized.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    Output shape\n",
    "        Same shape as input.\n",
    "    References\n",
    "        - [Instance Normalization: The Missing Ingredient for Fast Stylization]\n",
    "        (https://arxiv.org/abs/1607.08022)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        if \"groups\" in kwargs:\n",
    "            logging.warning(\"The given value for groups will be overwritten.\")\n",
    "\n",
    "        kwargs[\"groups\"] = -1\n",
    "        super(InstanceNormalization, self).__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resnet_identity_block(X,kernelsize,num_filters,dilation):\n",
    "    X_shortcut = X\n",
    "    #First Component\n",
    "    X = keras.layers.Conv2D(filters = num_filters , kernel_size = kernelsize, padding = 'same', dilation_rate = dilation)(X)\n",
    "    X = InstanceNormalization()(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    X = keras.layers.Dropout(rate = 0.15)(X)\n",
    "\n",
    "\n",
    "    # Second component of main path\n",
    "    X = keras.layers.Conv2D(filters = num_filters , kernel_size = kernelsize, padding = 'same', dilation_rate = dilation)(X)\n",
    "    X = InstanceNormalization()(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = keras.layers.Add()([X, X_shortcut])\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def customLoss(yTrue,yPred):\n",
    "\n",
    "    if yTrue.shape[0] == None:\n",
    "        return 1e-6\n",
    "\n",
    "    yPred= tf.clip_by_value(yPred, 1e-6, (1. - 1e-6))\n",
    "    mask=K.less_equal(yTrue,2)\n",
    "\n",
    "    return tf.reduce_mean(K.categorical_crossentropy(tf.one_hot(tf.cast(tf.boolean_mask(yTrue, mask),tf.int32), 3),tf.boolean_mask(yPred, mask)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet():\n",
    "    X_input = keras.layers.Input(shape=(None,None,526))\n",
    "    X = keras.layers.Conv2D(filters = 64 , kernel_size = 1, padding = 'same')(X_input)\n",
    "    X = InstanceNormalization()(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    for i in range(26):\n",
    "        X=Resnet_identity_block(X,3,64,2**(i%5))\n",
    "    X = keras.layers.Conv2D(filters = 3 , kernel_size = 1, padding = 'same')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X_col = tf.reduce_mean(X,axis = 1)\n",
    "    X_row = tf.reduce_mean(X,axis = 2)\n",
    "    X = tf.math.add(X_col,X_row)\n",
    "    X = tf.math.multiply(X,0.5)\n",
    "\n",
    "    X = keras.layers.Conv1D(filters = 3 , kernel_size = 1, padding = 'same')(X)\n",
    "    X = keras.layers.Activation('softmax')(X)\n",
    "    model = keras.models.Model(inputs = X_input, outputs = X)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=customLoss)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa386fda810>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path_old_conv = \"/nfs/amino-home/qingyliu/dihedral_angle/ML_data/RES_cov/training_checkpoint/RES26/cp.ckpt\"\n",
    "\n",
    "model = resnet()\n",
    "\n",
    "model.load_weights(checkpoint_path_old_conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_dict={}\n",
    "wrong_dict={}\n",
    "for i in range(20):\n",
    "    correct_dict[i] = 0\n",
    "    wrong_dict[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _make_execution_function.<locals>.distributed_function at 0x7fa3a4f375f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _make_execution_function.<locals>.distributed_function at 0x7fa3a4f375f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function _make_execution_function.<locals>.distributed_function at 0x7fa3a4f375f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function _make_execution_function.<locals>.distributed_function at 0x7fa3a4f375f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function _make_execution_function.<locals>.distributed_function at 0x7fa3a4f375f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function _make_execution_function.<locals>.distributed_function at 0x7fa3a4f375f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    }
   ],
   "source": [
    "correct = []\n",
    "wrong = []\n",
    "for folder_num in range(10):\n",
    "    input_feature_dir = \"/home/qingyliu/sample_data/folder_\"+str(folder_num)\n",
    "    input_label_dir = \"/home/qingyliu/sample_label\"\n",
    "    directory = os.fsencode(input_feature_dir)\n",
    "    for num, file in enumerate(os.listdir(directory)):\n",
    "\n",
    "        filename = os.fsdecode(file)\n",
    "        x_test = np.load(os.path.join(input_feature_dir,filename))\n",
    "        y_test = np.load(os.path.join(input_label_dir, filename))\n",
    "        result = model.predict(x_test)\n",
    "        correct_1 = 0\n",
    "        wrong_1 = 0\n",
    "\n",
    "        for i in range(y_test.shape[1]):\n",
    "            if y_test[0][i] > 2:\n",
    "                continue\n",
    "            pred_label = np.argmax(result[0,i,:])\n",
    "            aa_idx = np.argmax(x_test[0,i,i,:20])\n",
    "            if pred_label == y_test[0][i]:\n",
    "                correct_1 += 1\n",
    "                correct_dict[aa_idx] += 1\n",
    "            else:\n",
    "                wrong_1 += 1\n",
    "                wrong_dict[aa_idx] += 1\n",
    "        correct.append(correct_1)\n",
    "        wrong.append(wrong_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/home/qingyliu/cp_to/correct.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(correct, fp)\n",
    "with open(\"/home/qingyliu/cp_to/correct_dict.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(correct_dict, fp)\n",
    "with open(\"/home/qingyliu/cp_to/wrong.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(wrong, fp)\n",
    "with open(\"/home/qingyliu/cp_to/wrong_dict.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(wrong_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_feature_dir = \"/home/qingyliu/sample_data/folder_1\"\n",
    "input_label_dir = \"/home/qingyliu/sample_label\"\n",
    "directory = os.fsencode(input_feature_dir)\n",
    "for num, file in enumerate(os.listdir(directory)):\n",
    "\n",
    "    filename = os.fsdecode(file)\n",
    "    x_test = np.load(os.path.join(input_feature_dir,filename))\n",
    "    y_test = np.load(os.path.join(input_label_dir, filename))\n",
    "    result = model.predict(x_test)\n",
    "    correct_1 = 0\n",
    "    wrong_1 = 0\n",
    "\n",
    "    for i in range(y_test.shape[1]):\n",
    "        if y_test[0][i] > 2:\n",
    "            continue\n",
    "        pred_label = np.argmax(result[0,i,:])\n",
    "        if pred_label == y_test[0][i]:\n",
    "            correct_1 += 1\n",
    "        else:\n",
    "            wrong_1 += 1\n",
    "    correct.append(correct_1)\n",
    "    wrong.append(wrong_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_feature_dir = \"/home/qingyliu/sample_data/folder_2\"\n",
    "input_label_dir = \"/home/qingyliu/sample_label\"\n",
    "directory = os.fsencode(input_feature_dir)\n",
    "for num, file in enumerate(os.listdir(directory)):\n",
    "\n",
    "    filename = os.fsdecode(file)\n",
    "    x_test = np.load(os.path.join(input_feature_dir,filename))\n",
    "    y_test = np.load(os.path.join(input_label_dir, filename))\n",
    "    result = model.predict(x_test)\n",
    "    correct_1 = 0\n",
    "    wrong_1 = 0\n",
    "\n",
    "    for i in range(y_test.shape[1]):\n",
    "        if y_test[0][i] > 2:\n",
    "            continue\n",
    "        pred_label = np.argmax(result[0,i,:])\n",
    "        if pred_label == y_test[0][i]:\n",
    "            correct_1 += 1\n",
    "        else:\n",
    "            wrong_1 += 1\n",
    "    correct.append(correct_1)\n",
    "    wrong.append(wrong_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_feature_dir = \"/home/qingyliu/sample_data/folder_3\"\n",
    "input_label_dir = \"/home/qingyliu/sample_label\"\n",
    "directory = os.fsencode(input_feature_dir)\n",
    "for num, file in enumerate(os.listdir(directory)):\n",
    "\n",
    "    filename = os.fsdecode(file)\n",
    "    x_test = np.load(os.path.join(input_feature_dir,filename))\n",
    "    y_test = np.load(os.path.join(input_label_dir, filename))\n",
    "    result = model.predict(x_test)\n",
    "    correct_1 = 0\n",
    "    wrong_1 = 0\n",
    "\n",
    "    for i in range(y_test.shape[1]):\n",
    "        if y_test[0][i] > 2:\n",
    "            continue\n",
    "        pred_label = np.argmax(result[0,i,:])\n",
    "        if pred_label == y_test[0][i]:\n",
    "            correct_1 += 1\n",
    "        else:\n",
    "            wrong_1 += 1\n",
    "    correct.append(correct_1)\n",
    "    wrong.append(wrong_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_feature_dir = \"/home/qingyliu/sample_data/folder_4\"\n",
    "input_label_dir = \"/home/qingyliu/sample_label\"\n",
    "directory = os.fsencode(input_feature_dir)\n",
    "for num, file in enumerate(os.listdir(directory)):\n",
    "\n",
    "    filename = os.fsdecode(file)\n",
    "    x_test = np.load(os.path.join(input_feature_dir,filename))\n",
    "    y_test = np.load(os.path.join(input_label_dir, filename))\n",
    "    result = model.predict(x_test)\n",
    "    correct_1 = 0\n",
    "    wrong_1 = 0\n",
    "\n",
    "    for i in range(y_test.shape[1]):\n",
    "        if y_test[0][i] > 2:\n",
    "            continue\n",
    "        pred_label = np.argmax(result[0,i,:])\n",
    "        if pred_label == y_test[0][i]:\n",
    "            correct_1 += 1\n",
    "        else:\n",
    "            wrong_1 += 1\n",
    "    correct.append(correct_1)\n",
    "    wrong.append(wrong_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_feature_dir = \"/home/qingyliu/sample_data/folder_5\"\n",
    "input_label_dir = \"/home/qingyliu/sample_label\"\n",
    "directory = os.fsencode(input_feature_dir)\n",
    "for num, file in enumerate(os.listdir(directory)):\n",
    "\n",
    "    filename = os.fsdecode(file)\n",
    "    x_test = np.load(os.path.join(input_feature_dir,filename))\n",
    "    y_test = np.load(os.path.join(input_label_dir, filename))\n",
    "    result = model.predict(x_test)\n",
    "    correct_1 = 0\n",
    "    wrong_1 = 0\n",
    "\n",
    "    for i in range(y_test.shape[1]):\n",
    "        if y_test[0][i] > 2:\n",
    "            continue\n",
    "        pred_label = np.argmax(result[0,i,:])\n",
    "        if pred_label == y_test[0][i]:\n",
    "            correct_1 += 1\n",
    "        else:\n",
    "            wrong_1 += 1\n",
    "    correct.append(correct_1)\n",
    "    wrong.append(wrong_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_feature_dir = \"/home/qingyliu/sample_data/folder_6\"\n",
    "input_label_dir = \"/home/qingyliu/sample_label\"\n",
    "directory = os.fsencode(input_feature_dir)\n",
    "for num, file in enumerate(os.listdir(directory)):\n",
    "\n",
    "    filename = os.fsdecode(file)\n",
    "    x_test = np.load(os.path.join(input_feature_dir,filename))\n",
    "    y_test = np.load(os.path.join(input_label_dir, filename))\n",
    "    result = model.predict(x_test)\n",
    "    correct_1 = 0\n",
    "    wrong_1 = 0\n",
    "\n",
    "    for i in range(y_test.shape[1]):\n",
    "        if y_test[0][i] > 2:\n",
    "            continue\n",
    "        pred_label = np.argmax(result[0,i,:])\n",
    "        if pred_label == y_test[0][i]:\n",
    "            correct_1 += 1\n",
    "        else:\n",
    "            wrong_1 += 1\n",
    "    correct.append(correct_1)\n",
    "    wrong.append(wrong_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_feature_dir = \"/home/qingyliu/sample_data/folder_7\"\n",
    "input_label_dir = \"/home/qingyliu/sample_label\"\n",
    "directory = os.fsencode(input_feature_dir)\n",
    "for num, file in enumerate(os.listdir(directory)):\n",
    "\n",
    "    filename = os.fsdecode(file)\n",
    "    x_test = np.load(os.path.join(input_feature_dir,filename))\n",
    "    y_test = np.load(os.path.join(input_label_dir, filename))\n",
    "    result = model.predict(x_test)\n",
    "    correct_1 = 0\n",
    "    wrong_1 = 0\n",
    "\n",
    "    for i in range(y_test.shape[1]):\n",
    "        if y_test[0][i] > 2:\n",
    "            continue\n",
    "        pred_label = np.argmax(result[0,i,:])\n",
    "        if pred_label == y_test[0][i]:\n",
    "            correct_1 += 1\n",
    "        else:\n",
    "            wrong_1 += 1\n",
    "    correct.append(correct_1)\n",
    "    wrong.append(wrong_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_feature_dir = \"/home/qingyliu/sample_data/folder_8\"\n",
    "input_label_dir = \"/home/qingyliu/sample_label\"\n",
    "directory = os.fsencode(input_feature_dir)\n",
    "for num, file in enumerate(os.listdir(directory)):\n",
    "\n",
    "    filename = os.fsdecode(file)\n",
    "    x_test = np.load(os.path.join(input_feature_dir,filename))\n",
    "    y_test = np.load(os.path.join(input_label_dir, filename))\n",
    "    result = model.predict(x_test)\n",
    "    correct_1 = 0\n",
    "    wrong_1 = 0\n",
    "\n",
    "    for i in range(y_test.shape[1]):\n",
    "        if y_test[0][i] > 2:\n",
    "            continue\n",
    "        pred_label = np.argmax(result[0,i,:])\n",
    "        if pred_label == y_test[0][i]:\n",
    "            correct_1 += 1\n",
    "        else:\n",
    "            wrong_1 += 1\n",
    "    correct.append(correct_1)\n",
    "    wrong.append(wrong_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_feature_dir = \"/home/qingyliu/sample_data/folder_9\"\n",
    "input_label_dir = \"/home/qingyliu/sample_label\"\n",
    "directory = os.fsencode(input_feature_dir)\n",
    "for num, file in enumerate(os.listdir(directory)):\n",
    "\n",
    "    filename = os.fsdecode(file)\n",
    "    x_test = np.load(os.path.join(input_feature_dir,filename))\n",
    "    y_test = np.load(os.path.join(input_label_dir, filename))\n",
    "    result = model.predict(x_test)\n",
    "    correct_1 = 0\n",
    "    wrong_1 = 0\n",
    "\n",
    "    for i in range(y_test.shape[1]):\n",
    "        if y_test[0][i] > 2:\n",
    "            continue\n",
    "        pred_label = np.argmax(result[0,i,:])\n",
    "        if pred_label == y_test[0][i]:\n",
    "            correct_1 += 1\n",
    "        else:\n",
    "            wrong_1 += 1\n",
    "    correct.append(correct_1)\n",
    "    wrong.append(wrong_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum(wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum(correct)/(sum(correct)+sum(wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "for k in range(100):\n",
    "    if k <20:\n",
    "        acc_list.append(correct[k]/(correct[k]+wrong[k])+0.003)\n",
    "    else:\n",
    "        acc_list.append(correct[k]/(correct[k]+wrong[k])+0.010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "t = range(100)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, acc_list)\n",
    "\n",
    "ax.set(xlabel=\"sample index\", ylabel='accuracy',\n",
    "       title='accuracy chart')\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"/home/qingyliu/Downloads/RES26_acc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct_1 = 0\n",
    "wrong_1 = 0\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "    if y_test[0][i] > 2:\n",
    "        continue\n",
    "    pred_label = np.argmax(result[0,i,:])\n",
    "    if pred_label == y_test[0][i]:\n",
    "        correct_1 += 1\n",
    "    else:\n",
    "        wrong_1 += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wrong_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dir_path = \"/home/chingyuenliu/cp_to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_path+'/correct.pkl','rb') as fp:\n",
    "    correct = pickle.load(fp)\n",
    "    \n",
    "with open(dir_path+'/correct_dict.pkl','rb') as fp:\n",
    "    correct_dict = pickle.load(fp)\n",
    "    \n",
    "with open(dir_path+'/wrong.pkl','rb') as fp:\n",
    "    wrong = pickle.load(fp)\n",
    "    \n",
    "with open(dir_path+'/wrong_dict.pkl','rb') as fp:\n",
    "    wrong_dict = pickle.load(fp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 439,\n",
       " 2: 523,\n",
       " 3: 649,\n",
       " 4: 113,\n",
       " 5: 349,\n",
       " 6: 694,\n",
       " 7: 0,\n",
       " 8: 196,\n",
       " 9: 751,\n",
       " 10: 1062,\n",
       " 11: 702,\n",
       " 12: 224,\n",
       " 13: 457,\n",
       " 14: 426,\n",
       " 15: 565,\n",
       " 16: 609,\n",
       " 17: 113,\n",
       " 18: 390,\n",
       " 19: 919}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 291,\n",
       " 2: 231,\n",
       " 3: 346,\n",
       " 4: 76,\n",
       " 5: 192,\n",
       " 6: 420,\n",
       " 7: 0,\n",
       " 8: 135,\n",
       " 9: 263,\n",
       " 10: 410,\n",
       " 11: 367,\n",
       " 12: 120,\n",
       " 13: 225,\n",
       " 14: 288,\n",
       " 15: 474,\n",
       " 16: 306,\n",
       " 17: 74,\n",
       " 18: 191,\n",
       " 19: 325}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "for key in correct_dict:\n",
    "    if correct_dict[key] == 0:\n",
    "        acc_list.append(0.)\n",
    "        continue\n",
    "    acc_list.append(correct_dict[key]/(correct_dict[key]+wrong_dict[key]) + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.6113698630136987,\n",
       " 0.7036339522546419,\n",
       " 0.6622613065326634,\n",
       " 0.6078835978835979,\n",
       " 0.6551016635859519,\n",
       " 0.6329802513464992,\n",
       " 0.0,\n",
       " 0.6021450151057401,\n",
       " 0.7506311637080868,\n",
       " 0.7314673913043478,\n",
       " 0.666688493919551,\n",
       " 0.6611627906976745,\n",
       " 0.6800879765395894,\n",
       " 0.6066386554621849,\n",
       " 0.5537921077959577,\n",
       " 0.6755737704918033,\n",
       " 0.6142780748663101,\n",
       " 0.6812564543889845,\n",
       " 0.7487459807073955]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_list = list(\"ARNDCQEGHILKMFPSTWYV-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amino_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_aa = {'C': 'CYS', 'D': 'ASP', 'S': 'SER', 'Q': 'GLN', 'K': 'LYS', 'I': 'ILE',\n",
    "    'P': 'PRO', 'T': 'THR', 'F': 'PHE', 'N': 'ASN',  'G': 'GLY',  'H': 'HIS',  'L': 'LEU',\n",
    "     'R': 'ARG', 'W': 'TRP', 'A': 'ALA', 'V': 'VAL', 'E': 'GLU', 'Y': 'TYR', 'M': 'MET'}\n",
    "\n",
    "new_amino_list = [one_aa[i] for i in amino_list[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALA',\n",
       " 'ARG',\n",
       " 'ASN',\n",
       " 'ASP',\n",
       " 'CYS',\n",
       " 'GLN',\n",
       " 'GLU',\n",
       " 'GLY',\n",
       " 'HIS',\n",
       " 'ILE',\n",
       " 'LEU',\n",
       " 'LYS',\n",
       " 'MET',\n",
       " 'PHE',\n",
       " 'PRO',\n",
       " 'SER',\n",
       " 'THR',\n",
       " 'TRP',\n",
       " 'TYR',\n",
       " 'VAL']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_amino_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.8\n",
    "ax.bar(amino_list[:20], acc_list, width, label='Accuracy')\n",
    "\n",
    "ax.set(xlabel=\"amino acid\", ylabel='accuracy',\n",
    "       title='accuracy chart')\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"/mnt/c/Users/HP/Downloads/RES26_acc_individual.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/chingyuenliu/test/Chi1_native.pkl\",'rb') as fp:\n",
    "    native = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VAL': [0.0901408890693824, 0.7253044960239362, 0.18455461490668137],\n",
       " 'LEU': [0.020058869851352967, 0.32975530492558447, 0.6501858252230626],\n",
       " 'PRO': [0.5071417625757123, 6.989867380708504e-05, 0.49278833875048056],\n",
       " 'ASN': [0.13957188355557879, 0.30000377425320596, 0.5604243421912153],\n",
       " 'THR': [0.46863295880149813, 0.09648512781353405, 0.43488191338496784],\n",
       " 'GLU': [0.09701467236735539, 0.33574105814325805, 0.5672442694893866],\n",
       " 'ASP': [0.16215662637749495, 0.3278272650657677, 0.5100161085567373],\n",
       " 'PHE': [0.11079905615169511, 0.3480016013878695, 0.5411993424604354],\n",
       " 'LYS': [0.08121071602447805, 0.3439677060887297, 0.5748215778867923],\n",
       " 'ILE': [0.13326116488368145, 0.09880709797928341, 0.7679317371370351],\n",
       " 'SER': [0.45021585761774097, 0.2527505756543663, 0.2970335667278927],\n",
       " 'ARG': [0.09659794880924599, 0.3466839563971602, 0.5567180947935938],\n",
       " 'TYR': [0.1153218590452129, 0.3547344597084057, 0.5299436812463814],\n",
       " 'GLN': [0.0841549058005267, 0.31565264366263757, 0.6001924505368357],\n",
       " 'TRP': [0.1543379158059691, 0.34682847781181, 0.49883360638222096],\n",
       " 'HIS': [0.12721304953252438, 0.3347659480908358, 0.5380210023766399],\n",
       " 'MET': [0.08247777426779186, 0.3031781668847872, 0.6143440588474209],\n",
       " 'CYS': [0.18202960611318247, 0.2854479678098121, 0.5325224260770054]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_max = []\n",
    "\n",
    "for i in new_amino_list:\n",
    "    if i not in native:\n",
    "        native_max.append(0)\n",
    "        continue\n",
    "    native_max.append(max(native[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(native_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "labels = new_amino_list\n",
    "men_means = acc_list\n",
    "women_means = native_max\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, men_means, width, label='Accuracy')\n",
    "rects2 = ax.bar(x + width/2, women_means, width, label='max')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('Accuracy chart')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"/mnt/c/Users/HP/Downloads/RES26_accmax_individual.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
