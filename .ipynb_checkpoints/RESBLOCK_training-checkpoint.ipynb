{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Orginal implementation from keras_contrib/layer/normalization\n",
    "# =============================================================================\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "class GroupNormalization(tf.keras.layers.Layer):\n",
    "    \"\"\"Group normalization layer.\n",
    "    Group Normalization divides the channels into groups and computes\n",
    "    within each group the mean and variance for normalization.\n",
    "    Empirically, its accuracy is more stable than batch norm in a wide\n",
    "    range of small batch sizes, if learning rate is adjusted linearly\n",
    "    with batch sizes.\n",
    "    Relation to Layer Normalization:\n",
    "    If the number of groups is set to 1, then this operation becomes identical\n",
    "    to Layer Normalization.\n",
    "    Relation to Instance Normalization:\n",
    "    If the number of groups is set to the\n",
    "    input dimension (number of groups is equal\n",
    "    to number of channels), then this operation becomes\n",
    "    identical to Instance Normalization.\n",
    "    Arguments\n",
    "        groups: Integer, the number of groups for Group Normalization.\n",
    "            Can be in the range [1, N] where N is the input dimension.\n",
    "            The input dimension must be divisible by the number of groups.\n",
    "        axis: Integer, the axis that should be normalized.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    Output shape\n",
    "        Same shape as input.\n",
    "    References\n",
    "        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 groups=2,\n",
    "                 axis=-1,\n",
    "                 epsilon=1e-3,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(GroupNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.groups = groups\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = tf.keras.initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = tf.keras.initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = tf.keras.regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = tf.keras.regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = tf.keras.constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = tf.keras.constraints.get(gamma_constraint)\n",
    "        self._check_axis()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self._check_if_input_shape_is_none(input_shape)\n",
    "        self._set_number_of_groups_for_instance_norm(input_shape)\n",
    "        self._check_size_of_dimensions(input_shape)\n",
    "        self._create_input_spec(input_shape)\n",
    "\n",
    "        self._add_gamma_weight(input_shape)\n",
    "        self._add_beta_weight(input_shape)\n",
    "        self.built = True\n",
    "        super(GroupNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        input_shape = tf.keras.backend.int_shape(inputs)\n",
    "        tensor_input_shape = tf.shape(inputs)\n",
    "\n",
    "        reshaped_inputs, group_shape = self._reshape_into_groups(\n",
    "            inputs, input_shape, tensor_input_shape)\n",
    "\n",
    "        normalized_inputs = self._apply_normalization(reshaped_inputs,\n",
    "                                                      input_shape)\n",
    "\n",
    "        outputs = tf.reshape(normalized_inputs, tensor_input_shape)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'groups':\n",
    "            self.groups,\n",
    "            'axis':\n",
    "            self.axis,\n",
    "            'epsilon':\n",
    "            self.epsilon,\n",
    "            'center':\n",
    "            self.center,\n",
    "            'scale':\n",
    "            self.scale,\n",
    "            'beta_initializer':\n",
    "            tf.keras.initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer':\n",
    "            tf.keras.initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer':\n",
    "            tf.keras.regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer':\n",
    "            tf.keras.regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint':\n",
    "            tf.keras.constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint':\n",
    "            tf.keras.constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(GroupNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def _reshape_into_groups(self, inputs, input_shape, tensor_input_shape):\n",
    "\n",
    "        group_shape = [tensor_input_shape[i] for i in range(len(input_shape))]\n",
    "        group_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        group_shape.insert(self.axis, self.groups)\n",
    "        group_shape = tf.stack(group_shape)\n",
    "        reshaped_inputs = tf.reshape(inputs, group_shape)\n",
    "        return reshaped_inputs, group_shape\n",
    "\n",
    "    def _apply_normalization(self, reshaped_inputs, input_shape):\n",
    "\n",
    "        group_shape = tf.keras.backend.int_shape(reshaped_inputs)\n",
    "        group_reduction_axes = list(range(1, len(group_shape)))\n",
    "        axis = -2 if self.axis == -1 else self.axis - 1\n",
    "        group_reduction_axes.pop(axis)\n",
    "\n",
    "        mean, variance = tf.nn.moments(\n",
    "            reshaped_inputs, group_reduction_axes, keepdims=True)\n",
    "\n",
    "        gamma, beta = self._get_reshaped_weights(input_shape)\n",
    "        normalized_inputs = tf.nn.batch_normalization(\n",
    "            reshaped_inputs,\n",
    "            mean=mean,\n",
    "            variance=variance,\n",
    "            scale=gamma,\n",
    "            offset=beta,\n",
    "            variance_epsilon=self.epsilon)\n",
    "        return normalized_inputs\n",
    "\n",
    "    def _get_reshaped_weights(self, input_shape):\n",
    "        broadcast_shape = self._create_broadcast_shape(input_shape)\n",
    "        gamma = None\n",
    "        beta = None\n",
    "        if self.scale:\n",
    "            gamma = tf.reshape(self.gamma, broadcast_shape)\n",
    "\n",
    "        if self.center:\n",
    "            beta = tf.reshape(self.beta, broadcast_shape)\n",
    "        return gamma, beta\n",
    "\n",
    "    def _check_if_input_shape_is_none(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                             'input tensor should have a defined dimension '\n",
    "                             'but the layer received an input with shape ' +\n",
    "                             str(input_shape) + '.')\n",
    "\n",
    "    def _set_number_of_groups_for_instance_norm(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "\n",
    "        if self.groups == -1:\n",
    "            self.groups = dim\n",
    "\n",
    "    def _check_size_of_dimensions(self, input_shape):\n",
    "\n",
    "        dim = input_shape[self.axis]\n",
    "        if dim < self.groups:\n",
    "            raise ValueError(\n",
    "                'Number of groups (' + str(self.groups) + ') cannot be '\n",
    "                'more than the number of channels (' + str(dim) + ').')\n",
    "\n",
    "        if dim % self.groups != 0:\n",
    "            raise ValueError(\n",
    "                'Number of groups (' + str(self.groups) + ') must be a '\n",
    "                'multiple of the number of channels (' + str(dim) + ').')\n",
    "\n",
    "    def _check_axis(self):\n",
    "\n",
    "        if self.axis == 0:\n",
    "            raise ValueError(\n",
    "                \"You are trying to normalize your batch axis. Do you want to \"\n",
    "                \"use tf.layer.batch_normalization instead\")\n",
    "\n",
    "    def _create_input_spec(self, input_shape):\n",
    "\n",
    "        dim = input_shape[self.axis]\n",
    "        self.input_spec = tf.keras.layers.InputSpec(\n",
    "            ndim=len(input_shape), axes={self.axis: dim})\n",
    "\n",
    "    def _add_gamma_weight(self, input_shape):\n",
    "\n",
    "        dim = input_shape[self.axis]\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(\n",
    "                shape=shape,\n",
    "                name='gamma',\n",
    "                initializer=self.gamma_initializer,\n",
    "                regularizer=self.gamma_regularizer,\n",
    "                constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "\n",
    "    def _add_beta_weight(self, input_shape):\n",
    "\n",
    "        dim = input_shape[self.axis]\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(\n",
    "                shape=shape,\n",
    "                name='beta',\n",
    "                initializer=self.beta_initializer,\n",
    "                regularizer=self.beta_regularizer,\n",
    "                constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "\n",
    "    def _create_broadcast_shape(self, input_shape):\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        broadcast_shape.insert(self.axis, self.groups)\n",
    "        return broadcast_shape\n",
    "\n",
    "\n",
    "class InstanceNormalization(GroupNormalization):\n",
    "    \"\"\"Instance normalization layer.\n",
    "    Instance Normalization is an specific case of ```GroupNormalization```since\n",
    "    it normalizes all features of one channel. The Groupsize is equal to the\n",
    "    channel size. Empirically, its accuracy is more stable than batch norm in a\n",
    "    wide range of small batch sizes, if learning rate is adjusted linearly\n",
    "    with batch sizes.\n",
    "    Arguments\n",
    "        axis: Integer, the axis that should be normalized.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    Output shape\n",
    "        Same shape as input.\n",
    "    References\n",
    "        - [Instance Normalization: The Missing Ingredient for Fast Stylization]\n",
    "        (https://arxiv.org/abs/1607.08022)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        if \"groups\" in kwargs:\n",
    "            logging.warning(\"The given value for groups will be overwritten.\")\n",
    "\n",
    "        kwargs[\"groups\"] = -1\n",
    "        super(InstanceNormalization, self).__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resnet_identity_block(X,kernelsize,num_filters,dilation):\n",
    "    X_shortcut = X\n",
    "    #First Component\n",
    "    X = keras.layers.Conv2D(filters = num_filters , kernel_size = kernelsize, padding = 'same', dilation_rate = dilation)(X)\n",
    "    X = InstanceNormalization()(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    X = keras.layers.Dropout(rate = 0.15)(X)\n",
    "    \n",
    "    \n",
    "    # Second component of main path\n",
    "    X = keras.layers.Conv2D(filters = num_filters , kernel_size = kernelsize, padding = 'same', dilation_rate = dilation)(X)\n",
    "    X = InstanceNormalization()(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = keras.layers.Add()([X, X_shortcut])\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def customLoss(yTrue,yPred):\n",
    "\n",
    "    if yTrue.shape[0] == None:\n",
    "        return 1e-6\n",
    "\n",
    "    yPred= tf.clip_by_value(yPred, 1e-6, (1. - 1e-6))\n",
    "    mask=K.less_equal(yTrue,2)\n",
    "    \n",
    "    return tf.reduce_mean(K.categorical_crossentropy(tf.one_hot(tf.cast(tf.boolean_mask(yTrue, mask),tf.int32), 3),tf.boolean_mask(yPred, mask)))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow.keras.backend as K\n",
    "def crossentropy_cut(y_true,y_pred):\n",
    "    print(y_true.shape)\n",
    "    print(y_pred.shape)\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    y_pred_f= tf.clip_by_value(y_pred_f, 1e-7, (1. - 1e-7))\n",
    "    mask=K.greater_equal(y_true_f,-0.5)\n",
    "    losses = -(y_true_f * K.log(y_pred_f) + (1.0 - y_true_f) * K.log(1.0 - y_pred_f))\n",
    "    losses = tf.boolean_mask(losses, mask)\n",
    "    masked_loss = tf.reduce_mean(losses)\n",
    "    return masked_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet():\n",
    "    X_input = keras.layers.Input(shape=(None,None,526))\n",
    "    X = keras.layers.Conv2D(filters = 64 , kernel_size = 1, padding = 'same')(X_input)\n",
    "    X = InstanceNormalization()(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    for i in range(36):\n",
    "        X=Resnet_identity_block(X,3,64,2**(i%5))\n",
    "    X = keras.layers.Conv2D(filters = 3 , kernel_size = 1, padding = 'same')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X_col = tf.reduce_mean(X,axis = 1)\n",
    "    X_row = tf.reduce_mean(X,axis = 2)\n",
    "    X = tf.math.add(X_col,X_row)\n",
    "    X = tf.math.multiply(X,0.5)\n",
    "\n",
    "    X = keras.layers.Conv1D(filters = 3 , kernel_size = 1, padding = 'same')(X)\n",
    "    X = keras.layers.Activation('softmax')(X)\n",
    "    model = keras.models.Model(inputs = X_input, outputs = X)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=customLoss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_generator(input_feature_dir, input_label_dir,epochs):\n",
    "    directory = os.fsencode(input_feature_dir)\n",
    "    for j in range(epochs):\n",
    "        for file in os.listdir(directory):\n",
    "            \n",
    "            filename = os.fsdecode(file)\n",
    "            \n",
    "            yield np.load(os.path.join(input_feature_dir,filename)), np.expand_dims(np.load(os.path.join(input_label_dir,filename)),axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def input_generator(input_feature_dir, input_label_dir,epochs):\n",
    "    directory = os.fsencode(input_feature_dir)\n",
    "    for j in range(epochs):\n",
    "        for file in os.listdir(directory):\n",
    "            \n",
    "            filename = \"1o13A.npy\"\n",
    "\n",
    "            \n",
    "            yield np.load(\"/nfs/amino-home/qingyliu/dihedral_angle/conv_ML_input/1o13A_nonan.npy\"), np.expand_dims(np.load(os.path.join(input_label_dir,filename)),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_all_conv = \"/home/qingyliu/test/training_checkpoint/test\"\n",
    "checkpoint_dir_all_conv = os.path.dirname(checkpoint_path_all_conv)\n",
    "cp_callback_all_conv = tf.keras.callbacks.ModelCheckpoint(checkpoint_path_all_conv,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 save_freq=2        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "tf.Tensor(\n",
      "[[[0.04523649 0.02756625 0.9271973 ]\n",
      "  [0.03779402 0.01853066 0.9436753 ]\n",
      "  [0.0214019  0.02275299 0.9558452 ]\n",
      "  [0.00950449 0.00849987 0.9819956 ]\n",
      "  [0.03219226 0.04004664 0.9277611 ]\n",
      "  [0.03025194 0.04372558 0.92602247]\n",
      "  [0.02284286 0.01819427 0.95896286]\n",
      "  [0.03530921 0.02889338 0.93579745]\n",
      "  [0.01741496 0.01317086 0.9694141 ]\n",
      "  [0.03831286 0.02856178 0.93312544]\n",
      "  [0.03525956 0.02445778 0.9402827 ]\n",
      "  [0.04664297 0.03995806 0.913399  ]\n",
      "  [0.04479515 0.03667049 0.9185344 ]\n",
      "  [0.03519113 0.02556295 0.9392459 ]\n",
      "  [0.03072514 0.02064917 0.9486257 ]\n",
      "  [0.0362714  0.02610126 0.9376274 ]\n",
      "  [0.04277927 0.04338712 0.9138336 ]\n",
      "  [0.03486815 0.02858691 0.93654495]\n",
      "  [0.05411265 0.0500032  0.8958842 ]\n",
      "  [0.03652457 0.03630535 0.92717004]\n",
      "  [0.03265494 0.02079438 0.9465507 ]\n",
      "  [0.04160008 0.02619214 0.9322078 ]\n",
      "  [0.05105575 0.04015444 0.9087898 ]\n",
      "  [0.03355999 0.01890612 0.94753397]\n",
      "  [0.03055355 0.02270675 0.94673973]\n",
      "  [0.03240813 0.01781085 0.94978094]\n",
      "  [0.02106762 0.01213988 0.96679246]\n",
      "  [0.02768718 0.01639836 0.95591444]\n",
      "  [0.03680462 0.02093866 0.9422567 ]\n",
      "  [0.02584652 0.01304969 0.9611038 ]\n",
      "  [0.0395839  0.02512672 0.93528944]\n",
      "  [0.02221059 0.01057451 0.9672149 ]\n",
      "  [0.0257243  0.01603054 0.9582451 ]\n",
      "  [0.0198124  0.01168969 0.96849793]\n",
      "  [0.03483646 0.03485665 0.9303069 ]\n",
      "  [0.02871904 0.02536253 0.94591844]\n",
      "  [0.02839991 0.01865221 0.9529479 ]\n",
      "  [0.0275134  0.01970065 0.95278597]\n",
      "  [0.02072643 0.0122892  0.9669844 ]\n",
      "  [0.01779585 0.01059227 0.97161186]\n",
      "  [0.03265432 0.02271135 0.9446343 ]\n",
      "  [0.01707669 0.01050871 0.97241455]\n",
      "  [0.03133171 0.02319746 0.94547087]\n",
      "  [0.03156734 0.02497378 0.94345886]\n",
      "  [0.0359725  0.02787178 0.93615574]\n",
      "  [0.03204407 0.01844586 0.94951004]\n",
      "  [0.02784492 0.01826015 0.9538949 ]\n",
      "  [0.02329108 0.01494199 0.9617669 ]\n",
      "  [0.02619433 0.02009783 0.9537078 ]\n",
      "  [0.02862291 0.01997455 0.9514026 ]\n",
      "  [0.02437801 0.01503401 0.9605879 ]\n",
      "  [0.02209537 0.01245845 0.9654461 ]\n",
      "  [0.02047172 0.01127382 0.96825445]\n",
      "  [0.02508776 0.01578929 0.9591229 ]\n",
      "  [0.01303885 0.00631438 0.9806467 ]\n",
      "  [0.02687562 0.01574765 0.9573768 ]\n",
      "  [0.01817967 0.01494234 0.96687794]\n",
      "  [0.01076054 0.00434173 0.9848977 ]\n",
      "  [0.01948128 0.00983854 0.9706801 ]\n",
      "  [0.02338714 0.0127967  0.9638162 ]\n",
      "  [0.02024302 0.01102357 0.9687334 ]\n",
      "  [0.01720854 0.00803613 0.97475535]\n",
      "  [0.01716925 0.00888359 0.97394717]\n",
      "  [0.03448433 0.02341396 0.94210166]\n",
      "  [0.03063198 0.01867029 0.9506977 ]\n",
      "  [0.02388113 0.01470826 0.96141064]\n",
      "  [0.02291671 0.01355421 0.96352905]\n",
      "  [0.02644212 0.01397599 0.95958185]\n",
      "  [0.01589473 0.00755632 0.9765489 ]\n",
      "  [0.01969503 0.01034024 0.96996474]\n",
      "  [0.01971532 0.0146988  0.9655858 ]\n",
      "  [0.03159385 0.02739683 0.94100934]\n",
      "  [0.03069958 0.0210914  0.94820905]\n",
      "  [0.0232311  0.01094453 0.9658244 ]\n",
      "  [0.02988364 0.01840026 0.95171607]\n",
      "  [0.02512408 0.01075773 0.9641182 ]\n",
      "  [0.01994127 0.00988221 0.9701765 ]\n",
      "  [0.03555715 0.01959972 0.9448431 ]\n",
      "  [0.02851818 0.01840929 0.95307255]\n",
      "  [0.02271844 0.01085698 0.9664246 ]\n",
      "  [0.02924272 0.01615735 0.9545999 ]\n",
      "  [0.01273334 0.00677744 0.98048925]\n",
      "  [0.02170901 0.00967558 0.96861535]\n",
      "  [0.01341901 0.00544282 0.9811382 ]\n",
      "  [0.02103354 0.01177168 0.9671948 ]\n",
      "  [0.03007819 0.01674624 0.95317554]\n",
      "  [0.02385313 0.0103861  0.9657608 ]\n",
      "  [0.0235496  0.01088401 0.9655664 ]\n",
      "  [0.01389379 0.00505061 0.98105556]\n",
      "  [0.02205066 0.00934427 0.96860504]\n",
      "  [0.0204555  0.00857117 0.9709734 ]\n",
      "  [0.03235156 0.02254344 0.94510496]\n",
      "  [0.01835774 0.00813434 0.97350794]\n",
      "  [0.02633385 0.01123833 0.9624278 ]\n",
      "  [0.02855717 0.01572476 0.9557181 ]\n",
      "  [0.02790357 0.01566066 0.95643574]\n",
      "  [0.03621092 0.01871057 0.94507855]\n",
      "  [0.05898319 0.04347058 0.89754623]\n",
      "  [0.0486282  0.03074101 0.92063075]\n",
      "  [0.03241168 0.02044343 0.94714487]\n",
      "  [0.0449698  0.03334738 0.92168283]\n",
      "  [0.04435529 0.02973294 0.9259118 ]\n",
      "  [0.06015879 0.05486863 0.8849726 ]\n",
      "  [0.02901434 0.0123162  0.9586695 ]\n",
      "  [0.03487002 0.01386324 0.95126677]\n",
      "  [0.02280582 0.0068573  0.9703369 ]\n",
      "  [0.02206697 0.00622031 0.97171265]]], shape=(1, 107, 3), dtype=float32)\n",
      "WARNING:tensorflow:From /home/qingyliu/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_grad.py:502: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n",
      "1/5 [=====>........................] - ETA: 34s - loss: 1.7710tf.Tensor(\n",
      "[[[4.99583874e-03 8.72930686e-04 9.94131267e-01]\n",
      "  [1.03173754e-03 8.57280393e-05 9.98882592e-01]\n",
      "  [1.15791243e-03 2.21621667e-04 9.98620510e-01]\n",
      "  [8.53588572e-04 1.43633748e-04 9.99002755e-01]\n",
      "  [1.08352350e-02 3.56451119e-03 9.85600233e-01]\n",
      "  [1.05949314e-02 4.18362627e-03 9.85221446e-01]\n",
      "  [1.06929587e-02 3.80588928e-03 9.85501111e-01]\n",
      "  [1.21039143e-02 4.17007180e-03 9.83726084e-01]\n",
      "  [7.69858994e-03 3.18304868e-03 9.89118338e-01]\n",
      "  [1.01886746e-02 3.79347173e-03 9.86017823e-01]\n",
      "  [8.54239054e-03 3.74539266e-03 9.87712204e-01]\n",
      "  [8.91947933e-03 4.47694678e-03 9.86603618e-01]\n",
      "  [6.99271448e-03 2.12328462e-03 9.90884006e-01]\n",
      "  [1.05927819e-02 4.45708493e-03 9.84950185e-01]\n",
      "  [1.09043084e-02 3.88510595e-03 9.85210598e-01]\n",
      "  [2.36600749e-02 1.29750920e-02 9.63364840e-01]\n",
      "  [5.20220213e-02 2.25826532e-01 7.22151458e-01]\n",
      "  [4.62034121e-02 2.51971781e-01 7.01824784e-01]\n",
      "  [4.24943492e-02 1.12211913e-01 8.45293760e-01]\n",
      "  [4.18379083e-02 1.06218353e-01 8.51943731e-01]\n",
      "  [3.81907336e-02 7.92893246e-02 8.82519960e-01]\n",
      "  [3.07521541e-02 6.96504414e-02 8.99597406e-01]\n",
      "  [2.59386674e-02 3.37573551e-02 9.40303981e-01]\n",
      "  [2.67885961e-02 5.33722863e-02 9.19839084e-01]\n",
      "  [1.65465698e-02 2.02168263e-02 9.63236630e-01]\n",
      "  [2.32669767e-02 2.53304802e-02 9.51402605e-01]\n",
      "  [2.53245421e-02 4.06063832e-02 9.34069037e-01]\n",
      "  [1.96773075e-02 2.79963277e-02 9.52326417e-01]\n",
      "  [2.49492656e-02 2.95456666e-02 9.45505083e-01]\n",
      "  [4.25355360e-02 7.15068728e-02 8.85957599e-01]\n",
      "  [2.20567081e-02 2.10543759e-02 9.56888914e-01]\n",
      "  [3.51796672e-02 5.81320301e-02 9.06688333e-01]\n",
      "  [3.22727449e-02 9.87178311e-02 8.69009435e-01]\n",
      "  [1.73985064e-02 2.45800372e-02 9.58021402e-01]\n",
      "  [2.67052110e-02 7.13414326e-02 9.01953340e-01]\n",
      "  [2.19734237e-02 7.29689300e-02 9.05057609e-01]\n",
      "  [1.92839149e-02 5.58422543e-02 9.24873888e-01]\n",
      "  [2.70709433e-02 5.57139367e-02 9.17215109e-01]\n",
      "  [2.72618085e-02 6.37294948e-02 9.09008741e-01]\n",
      "  [1.37380660e-02 2.79207975e-02 9.58341122e-01]\n",
      "  [3.03429831e-02 1.57631621e-01 8.12025368e-01]\n",
      "  [2.73620691e-02 5.77304661e-02 9.14907455e-01]\n",
      "  [2.51364242e-02 5.38711920e-02 9.20992434e-01]\n",
      "  [2.91928034e-02 8.09075609e-02 8.89899671e-01]\n",
      "  [2.61025727e-02 1.02082737e-01 8.71814728e-01]\n",
      "  [1.89071707e-02 3.10684685e-02 9.50024366e-01]\n",
      "  [2.26143263e-02 5.20533659e-02 9.25332248e-01]\n",
      "  [2.19128765e-02 5.64577579e-02 9.21629369e-01]\n",
      "  [2.96333674e-02 7.94731081e-02 8.90893519e-01]\n",
      "  [2.79988013e-02 6.55767396e-02 9.06424403e-01]\n",
      "  [2.32838634e-02 9.04648304e-02 8.86251330e-01]\n",
      "  [2.97553893e-02 1.12837359e-01 8.57407272e-01]\n",
      "  [2.56290268e-02 1.09628990e-01 8.64741981e-01]\n",
      "  [2.71400716e-02 8.69087726e-02 8.85951161e-01]\n",
      "  [2.58386116e-02 9.98997614e-02 8.74261558e-01]\n",
      "  [3.30509171e-02 9.45880637e-02 8.72361004e-01]\n",
      "  [2.85317283e-02 9.55088958e-02 8.75959456e-01]\n",
      "  [2.81513389e-02 8.06090534e-02 8.91239583e-01]\n",
      "  [4.62531894e-02 9.17132497e-02 8.62033546e-01]\n",
      "  [3.96898165e-02 1.71966761e-01 7.88343430e-01]\n",
      "  [3.45810838e-02 7.30105564e-02 8.92408311e-01]\n",
      "  [2.81017795e-02 5.91853447e-02 9.12712872e-01]\n",
      "  [2.70380508e-02 5.50871789e-02 9.17874753e-01]\n",
      "  [2.37110127e-02 5.12729026e-02 9.25016046e-01]\n",
      "  [2.36880910e-02 3.26573774e-02 9.43654597e-01]\n",
      "  [2.11370941e-02 3.36455032e-02 9.45217431e-01]\n",
      "  [2.40058117e-02 8.89264867e-02 8.87067676e-01]\n",
      "  [3.17869633e-02 1.16057910e-01 8.52155089e-01]\n",
      "  [3.18218246e-02 7.82075599e-02 8.89970541e-01]\n",
      "  [2.29640435e-02 7.15233907e-02 9.05512571e-01]\n",
      "  [2.81833690e-02 7.03826249e-02 9.01434004e-01]\n",
      "  [2.54710764e-02 5.97048402e-02 9.14824009e-01]\n",
      "  [4.69410457e-02 1.54602021e-01 7.98456967e-01]\n",
      "  [3.00161801e-02 6.26108125e-02 9.07373011e-01]\n",
      "  [2.66455468e-02 3.49569656e-02 9.38397467e-01]\n",
      "  [1.19018229e-02 8.18233564e-03 9.79915857e-01]\n",
      "  [9.10547655e-03 7.06640072e-03 9.83828187e-01]\n",
      "  [7.30004162e-03 4.50394955e-03 9.88196015e-01]\n",
      "  [8.49226210e-03 5.34369657e-03 9.86164033e-01]\n",
      "  [1.06001943e-02 7.64373271e-03 9.81756091e-01]\n",
      "  [1.30304042e-02 1.26619190e-02 9.74307716e-01]\n",
      "  [7.43015157e-03 5.75234555e-03 9.86817479e-01]\n",
      "  [1.00288261e-02 8.61987472e-03 9.81351376e-01]\n",
      "  [8.11730232e-03 8.42788164e-03 9.83454823e-01]\n",
      "  [7.53424596e-03 6.08545449e-03 9.86380279e-01]\n",
      "  [1.32985422e-02 1.22015709e-02 9.74499881e-01]\n",
      "  [9.29496065e-03 5.15103713e-03 9.85554039e-01]\n",
      "  [9.43336356e-03 5.26043074e-03 9.85306144e-01]\n",
      "  [1.02237975e-02 6.03602268e-03 9.83740151e-01]\n",
      "  [8.09502229e-03 2.97315093e-03 9.88931775e-01]\n",
      "  [8.41215253e-03 5.92058059e-03 9.85667288e-01]\n",
      "  [8.69777799e-03 5.41485380e-03 9.85887349e-01]\n",
      "  [7.96609279e-03 6.12033624e-03 9.85913575e-01]\n",
      "  [1.09190308e-02 5.12881577e-03 9.83952105e-01]\n",
      "  [1.55698266e-02 1.14583764e-02 9.72971857e-01]\n",
      "  [1.23095540e-02 1.18700368e-02 9.75820422e-01]\n",
      "  [1.93736684e-02 2.12177318e-02 9.59408581e-01]\n",
      "  [1.52843986e-02 1.27130374e-02 9.72002625e-01]\n",
      "  [8.80390964e-03 5.91459312e-03 9.85281527e-01]\n",
      "  [1.59181785e-02 1.47898151e-02 9.69292045e-01]\n",
      "  [1.31319389e-02 1.45551721e-02 9.72312868e-01]\n",
      "  [1.29115749e-02 1.15854228e-02 9.75503027e-01]\n",
      "  [1.45166656e-02 1.59194246e-02 9.69563961e-01]\n",
      "  [8.35192855e-03 2.26272433e-03 9.89385426e-01]\n",
      "  [9.19411890e-03 2.00684112e-03 9.88799036e-01]\n",
      "  [9.50733025e-04 6.87330103e-05 9.98980463e-01]\n",
      "  [5.89485397e-04 4.01219113e-05 9.99370396e-01]]], shape=(1, 107, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to /home/qingyliu/test/training_checkpoint/test\n",
      "2/5 [===========>..................] - ETA: 19s - loss: 1.6272tf.Tensor(\n",
      "[[[1.86153799e-01 5.54522097e-01 2.59324074e-01]\n",
      "  [1.77870035e-01 4.89980876e-01 3.32149148e-01]\n",
      "  [6.35022968e-02 8.11306238e-01 1.25191540e-01]\n",
      "  [5.85028045e-02 7.95680165e-01 1.45816937e-01]\n",
      "  [1.08801864e-01 7.46883273e-01 1.44314915e-01]\n",
      "  [1.33361846e-01 6.88598335e-01 1.78039819e-01]\n",
      "  [1.00848183e-01 7.55116284e-01 1.44035593e-01]\n",
      "  [9.18378830e-02 7.84413218e-01 1.23748966e-01]\n",
      "  [9.05434564e-02 7.12318182e-01 1.97138414e-01]\n",
      "  [3.81572619e-02 9.00862575e-01 6.09801672e-02]\n",
      "  [8.46309364e-02 7.49600232e-01 1.65768802e-01]\n",
      "  [4.92536165e-02 8.54125202e-01 9.66211781e-02]\n",
      "  [1.14509746e-01 6.45271957e-01 2.40218282e-01]\n",
      "  [6.17174096e-02 7.96570480e-01 1.41712159e-01]\n",
      "  [7.54487664e-02 7.54574716e-01 1.69976473e-01]\n",
      "  [7.25283846e-02 7.97837079e-01 1.29634529e-01]\n",
      "  [6.93743932e-04 9.98272777e-01 1.03338179e-03]\n",
      "  [5.18232235e-04 9.98721182e-01 7.60579715e-04]\n",
      "  [7.26062630e-04 9.98091161e-01 1.18284649e-03]\n",
      "  [1.92946289e-03 9.95240569e-01 2.82991002e-03]\n",
      "  [2.50995695e-03 9.92669940e-01 4.82008746e-03]\n",
      "  [3.14284908e-03 9.91193354e-01 5.66388154e-03]\n",
      "  [1.03354938e-02 9.65143323e-01 2.45211720e-02]\n",
      "  [5.55259082e-03 9.79732156e-01 1.47152795e-02]\n",
      "  [6.15799008e-03 9.76869643e-01 1.69723723e-02]\n",
      "  [5.27070556e-03 9.81627762e-01 1.31016010e-02]\n",
      "  [2.85263499e-03 9.89650488e-01 7.49691529e-03]\n",
      "  [6.58505410e-03 9.74492431e-01 1.89225897e-02]\n",
      "  [7.22534163e-03 9.71436739e-01 2.13378109e-02]\n",
      "  [4.47370717e-03 9.86003935e-01 9.52237006e-03]\n",
      "  [4.39780857e-03 9.85062957e-01 1.05391657e-02]\n",
      "  [3.83258867e-03 9.88143623e-01 8.02377984e-03]\n",
      "  [2.51551741e-03 9.89823401e-01 7.66105205e-03]\n",
      "  [4.17715125e-03 9.79942858e-01 1.58799719e-02]\n",
      "  [1.67561858e-03 9.93940711e-01 4.38364642e-03]\n",
      "  [3.37601895e-03 9.83105600e-01 1.35183334e-02]\n",
      "  [2.93051498e-03 9.88191903e-01 8.87750369e-03]\n",
      "  [3.01385997e-03 9.84456360e-01 1.25298239e-02]\n",
      "  [3.48001486e-03 9.83936310e-01 1.25836618e-02]\n",
      "  [3.54060042e-03 9.76660252e-01 1.97992213e-02]\n",
      "  [2.06605997e-03 9.92110848e-01 5.82308136e-03]\n",
      "  [2.48394511e-03 9.90163326e-01 7.35275121e-03]\n",
      "  [3.49750323e-03 9.78877366e-01 1.76252201e-02]\n",
      "  [4.34640842e-03 9.76299107e-01 1.93545371e-02]\n",
      "  [4.12318390e-03 9.81169760e-01 1.47070289e-02]\n",
      "  [6.11155247e-03 9.64534998e-01 2.93535311e-02]\n",
      "  [2.68432801e-03 9.83621359e-01 1.36942985e-02]\n",
      "  [4.09232778e-03 9.70715761e-01 2.51918640e-02]\n",
      "  [4.03891969e-03 9.79058802e-01 1.69022009e-02]\n",
      "  [3.06400075e-03 9.81961548e-01 1.49744535e-02]\n",
      "  [4.42513963e-03 9.73574400e-01 2.20005568e-02]\n",
      "  [2.49142968e-03 9.88293767e-01 9.21478309e-03]\n",
      "  [3.08522210e-03 9.82436419e-01 1.44784423e-02]\n",
      "  [4.16588876e-03 9.69726324e-01 2.61077508e-02]\n",
      "  [4.00061486e-03 9.74106729e-01 2.18925737e-02]\n",
      "  [2.20506289e-03 9.89723325e-01 8.07160977e-03]\n",
      "  [3.31583549e-03 9.78565872e-01 1.81184188e-02]\n",
      "  [1.79476186e-03 9.90089417e-01 8.11585691e-03]\n",
      "  [2.55826046e-03 9.86007333e-01 1.14344051e-02]\n",
      "  [2.12565786e-03 9.87959743e-01 9.91453789e-03]\n",
      "  [3.14485142e-03 9.83983994e-01 1.28712598e-02]\n",
      "  [5.58407698e-03 9.66535628e-01 2.78803408e-02]\n",
      "  [4.50130645e-03 9.76813078e-01 1.86855588e-02]\n",
      "  [5.23390621e-03 9.68310654e-01 2.64554638e-02]\n",
      "  [6.02310058e-03 9.60758269e-01 3.32187042e-02]\n",
      "  [3.43311671e-03 9.76399660e-01 2.01671738e-02]\n",
      "  [2.17186916e-03 9.86969471e-01 1.08586624e-02]\n",
      "  [2.57987110e-03 9.87561047e-01 9.85913165e-03]\n",
      "  [2.18283734e-03 9.88302410e-01 9.51473136e-03]\n",
      "  [3.71029624e-03 9.81830657e-01 1.44590940e-02]\n",
      "  [2.00203457e-03 9.88387644e-01 9.61028878e-03]\n",
      "  [5.18672401e-03 9.68572497e-01 2.62407567e-02]\n",
      "  [1.31081091e-03 9.94543195e-01 4.14596405e-03]\n",
      "  [4.79479367e-03 9.66981947e-01 2.82232538e-02]\n",
      "  [1.05861519e-02 9.26092505e-01 6.33213148e-02]\n",
      "  [2.81416941e-02 5.78133881e-01 3.93724471e-01]\n",
      "  [1.67580172e-02 7.69258618e-01 2.13983327e-01]\n",
      "  [1.81859042e-02 7.49271154e-01 2.32542932e-01]\n",
      "  [2.02182233e-02 7.29256809e-01 2.50525028e-01]\n",
      "  [3.41379903e-02 5.17265022e-01 4.48597014e-01]\n",
      "  [2.19715238e-02 7.00539052e-01 2.77489364e-01]\n",
      "  [1.69006847e-02 7.43131638e-01 2.39967704e-01]\n",
      "  [2.97263619e-02 5.86977720e-01 3.83295864e-01]\n",
      "  [2.08873581e-02 7.67262220e-01 2.11850405e-01]\n",
      "  [1.76593829e-02 7.80472636e-01 2.01868013e-01]\n",
      "  [1.41360844e-02 8.83512557e-01 1.02351330e-01]\n",
      "  [3.65424417e-02 4.71403718e-01 4.92053807e-01]\n",
      "  [2.75402889e-02 7.61564970e-01 2.10894689e-01]\n",
      "  [2.80758571e-02 6.69160247e-01 3.02763879e-01]\n",
      "  [2.64830738e-02 6.59725010e-01 3.13791931e-01]\n",
      "  [1.70527641e-02 8.20627749e-01 1.62319466e-01]\n",
      "  [1.35630742e-02 9.29955840e-01 5.64810671e-02]\n",
      "  [9.36107803e-03 9.55528677e-01 3.51102725e-02]\n",
      "  [1.23571604e-02 9.48161006e-01 3.94818522e-02]\n",
      "  [1.08525408e-02 9.61626768e-01 2.75206193e-02]\n",
      "  [4.20201803e-03 9.86553371e-01 9.24459379e-03]\n",
      "  [3.05311289e-03 9.91375148e-01 5.57175651e-03]\n",
      "  [3.45094339e-03 9.88200545e-01 8.34856834e-03]\n",
      "  [4.48947912e-03 9.81892288e-01 1.36182932e-02]\n",
      "  [5.04754856e-03 9.85800564e-01 9.15178284e-03]\n",
      "  [5.97110903e-03 9.84204710e-01 9.82422009e-03]\n",
      "  [3.28561943e-03 9.90981638e-01 5.73272584e-03]\n",
      "  [8.72557866e-04 9.97877598e-01 1.24986598e-03]\n",
      "  [8.74366146e-03 9.77967918e-01 1.32883806e-02]\n",
      "  [2.22974848e-02 9.40917909e-01 3.67846042e-02]\n",
      "  [8.07431191e-02 6.99207425e-01 2.20049456e-01]\n",
      "  [5.51266521e-02 7.70367563e-01 1.74505726e-01]]], shape=(1, 107, 3), dtype=float32)\n",
      "3/5 [=================>............] - ETA: 13s - loss: 1.7938tf.Tensor(\n",
      "[[[3.21564555e-01 3.35614473e-01 3.42820972e-01]\n",
      "  [2.90476859e-01 3.83821696e-01 3.25701445e-01]\n",
      "  [2.18561739e-01 5.17838061e-01 2.63600260e-01]\n",
      "  [1.81022242e-01 5.91936827e-01 2.27040917e-01]\n",
      "  [1.50814205e-01 6.89958870e-01 1.59226984e-01]\n",
      "  [1.74591511e-01 6.35258436e-01 1.90150112e-01]\n",
      "  [1.37580648e-01 7.03747094e-01 1.58672214e-01]\n",
      "  [1.97763562e-01 5.62854826e-01 2.39381611e-01]\n",
      "  [1.00551315e-01 6.23462379e-01 2.75986344e-01]\n",
      "  [9.64668766e-02 7.45884120e-01 1.57649010e-01]\n",
      "  [1.37147665e-01 5.63838005e-01 2.99014360e-01]\n",
      "  [1.57887369e-01 5.67377210e-01 2.74735421e-01]\n",
      "  [9.74771455e-02 6.97327018e-01 2.05195874e-01]\n",
      "  [1.10493772e-01 5.84139347e-01 3.05366874e-01]\n",
      "  [1.15152694e-01 5.84597886e-01 3.00249428e-01]\n",
      "  [1.39825493e-01 4.79464442e-01 3.80710095e-01]\n",
      "  [1.54325971e-03 9.94343042e-01 4.11369931e-03]\n",
      "  [2.29476485e-03 9.88917351e-01 8.78787320e-03]\n",
      "  [8.78439844e-03 9.42392409e-01 4.88232262e-02]\n",
      "  [3.40984315e-02 7.67756224e-01 1.98145390e-01]\n",
      "  [2.65376344e-02 7.32740700e-01 2.40721673e-01]\n",
      "  [3.35666053e-02 4.70563561e-01 4.95869815e-01]\n",
      "  [5.40625192e-02 3.87537599e-01 5.58399856e-01]\n",
      "  [4.03389670e-02 5.10348916e-01 4.49312091e-01]\n",
      "  [4.47647162e-02 2.68813819e-01 6.86421454e-01]\n",
      "  [3.84022519e-02 1.37161478e-01 8.24436307e-01]\n",
      "  [3.67689654e-02 1.95134014e-01 7.68097043e-01]\n",
      "  [4.30820435e-02 1.87068000e-01 7.69849896e-01]\n",
      "  [4.82812934e-02 1.54992014e-01 7.96726704e-01]\n",
      "  [4.28418145e-02 4.32845712e-01 5.24312496e-01]\n",
      "  [3.59544680e-02 1.17629692e-01 8.46415818e-01]\n",
      "  [3.82841527e-02 1.55973896e-01 8.05741906e-01]\n",
      "  [1.24384658e-02 8.59959573e-02 9.01565611e-01]\n",
      "  [7.69723952e-03 2.56622732e-02 9.66640532e-01]\n",
      "  [2.05645729e-02 2.07477480e-01 7.71957994e-01]\n",
      "  [1.74160097e-02 1.34434402e-01 8.48149538e-01]\n",
      "  [1.29226781e-02 6.52158111e-02 9.21861529e-01]\n",
      "  [6.87017152e-03 2.31042821e-02 9.70025539e-01]\n",
      "  [2.10878905e-02 1.25320256e-01 8.53591859e-01]\n",
      "  [9.85458866e-03 4.17914502e-02 9.48353946e-01]\n",
      "  [1.11572184e-02 1.43091366e-01 8.45751464e-01]\n",
      "  [1.65665224e-02 7.98493102e-02 9.03584182e-01]\n",
      "  [7.87001476e-03 1.74893979e-02 9.74640608e-01]\n",
      "  [1.12749077e-02 4.09797095e-02 9.47745383e-01]\n",
      "  [1.22362636e-02 1.29352689e-01 8.58411014e-01]\n",
      "  [1.10485451e-02 2.08051689e-02 9.68146265e-01]\n",
      "  [9.49873962e-03 2.80290190e-02 9.62472260e-01]\n",
      "  [8.81553162e-03 2.41973773e-02 9.66987073e-01]\n",
      "  [8.57574027e-03 3.12487017e-02 9.60175514e-01]\n",
      "  [1.18749607e-02 5.09605333e-02 9.37164485e-01]\n",
      "  [7.55457161e-03 2.29171924e-02 9.69528198e-01]\n",
      "  [1.25800427e-02 4.36196886e-02 9.43800271e-01]\n",
      "  [8.23283661e-03 3.17449272e-02 9.60022211e-01]\n",
      "  [6.26895996e-03 1.53295994e-02 9.78401482e-01]\n",
      "  [7.63681764e-03 3.89658622e-02 9.53397274e-01]\n",
      "  [1.28516359e-02 5.78141548e-02 9.29334164e-01]\n",
      "  [3.19269020e-03 7.01395469e-03 9.89793420e-01]\n",
      "  [5.58809284e-03 1.02131721e-02 9.84198689e-01]\n",
      "  [9.47057921e-03 5.32523096e-02 9.37277138e-01]\n",
      "  [7.72030884e-03 3.83276232e-02 9.53952074e-01]\n",
      "  [7.74191832e-03 2.06954405e-02 9.71562684e-01]\n",
      "  [9.16027371e-03 4.17788029e-02 9.49060917e-01]\n",
      "  [1.28122056e-02 6.48567826e-02 9.22331035e-01]\n",
      "  [8.72288551e-03 3.33943330e-02 9.57882822e-01]\n",
      "  [1.13584902e-02 4.82249409e-02 9.40416574e-01]\n",
      "  [6.69049984e-03 1.96023192e-02 9.73707139e-01]\n",
      "  [1.10167125e-02 4.34809700e-02 9.45502281e-01]\n",
      "  [1.01047857e-02 2.81656533e-01 7.08238721e-01]\n",
      "  [6.83631143e-03 2.06462573e-02 9.72517490e-01]\n",
      "  [1.28929159e-02 7.42751732e-02 9.12831962e-01]\n",
      "  [1.43243819e-02 3.42105389e-01 6.43570185e-01]\n",
      "  [8.87667947e-03 4.22702767e-02 9.48853076e-01]\n",
      "  [1.19167734e-02 1.90956727e-01 7.97126472e-01]\n",
      "  [8.49833153e-03 2.69418508e-02 9.64559853e-01]\n",
      "  [8.82540457e-03 1.48943551e-02 9.76280272e-01]\n",
      "  [1.71579362e-03 6.86171756e-04 9.97597992e-01]\n",
      "  [1.58010575e-03 4.81061725e-04 9.97938812e-01]\n",
      "  [1.13916048e-03 2.99156061e-04 9.98561680e-01]\n",
      "  [1.41228025e-03 5.98991348e-04 9.97988701e-01]\n",
      "  [1.93360401e-03 5.70904347e-04 9.97495472e-01]\n",
      "  [9.80669749e-04 4.91739251e-04 9.98527527e-01]\n",
      "  [1.33923406e-03 5.16901142e-04 9.98143911e-01]\n",
      "  [2.04688450e-03 7.90725520e-04 9.97162402e-01]\n",
      "  [1.82047090e-03 8.00143345e-04 9.97379422e-01]\n",
      "  [1.84297888e-03 1.15625816e-03 9.97000754e-01]\n",
      "  [4.71551018e-03 6.18500542e-03 9.89099443e-01]\n",
      "  [2.01493106e-03 8.34270904e-04 9.97150838e-01]\n",
      "  [3.77335260e-03 1.60505029e-03 9.94621634e-01]\n",
      "  [2.77501321e-03 1.33031840e-03 9.95894670e-01]\n",
      "  [2.64687114e-03 9.56544711e-04 9.96396601e-01]\n",
      "  [4.27948218e-03 1.79782021e-03 9.93922651e-01]\n",
      "  [4.13371436e-02 4.86266054e-02 9.10036266e-01]\n",
      "  [6.17434755e-02 4.95111644e-02 8.88745368e-01]\n",
      "  [6.18923865e-02 8.33766237e-02 8.54731023e-01]\n",
      "  [1.15798227e-01 1.95202440e-01 6.88999295e-01]\n",
      "  [1.10730141e-01 1.94045976e-01 6.95223927e-01]\n",
      "  [1.30089596e-01 2.16982931e-01 6.52927458e-01]\n",
      "  [9.94073749e-02 1.54714018e-01 7.45878577e-01]\n",
      "  [1.07254438e-01 2.03906327e-01 6.88839197e-01]\n",
      "  [7.57124573e-02 7.44566023e-01 1.79721490e-01]\n",
      "  [9.17865634e-02 6.92342341e-01 2.15871096e-01]\n",
      "  [8.61575603e-02 7.50867665e-01 1.62974834e-01]\n",
      "  [1.52763333e-02 9.62846339e-01 2.18772981e-02]\n",
      "  [2.13722810e-01 4.72459763e-01 3.13817471e-01]\n",
      "  [2.52606481e-01 3.87424916e-01 3.59968603e-01]\n",
      "  [2.51164079e-01 2.44149998e-01 5.04685879e-01]\n",
      "  [2.48272017e-01 3.06614697e-01 4.45113301e-01]]], shape=(1, 107, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit_generator(input_generator(\"/nfs/amino-home/qingyliu/dihedral_angle/conv_ML_input\", \"/nfs/amino-home/qingyliu/dihedral_angle/chi1_label\",epochs = 500),\n",
    "                             steps_per_epoch = 5,\n",
    "                             epochs = 500,\n",
    "                             callbacks = [cp_callback_all_conv])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
